# -*- coding: utf-8 -*-
"""Big mart sales prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KykbbDrPUCSJ0j73SGlsYvb1YigFkNPu

Importing the dependencies
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from xgboost import XGBRegressor
from sklearn import metrics

"""Data collection and transformation"""

#loading the dataset file into pandas dataframe
sales_data = pd.read_csv('/content/big mart sales.csv')

#printing the first 5 rows of the dataset
sales_data.head()

#nubmer of rows and columns
sales_data.shape

#getting the information about the dataset
sales_data.info()

"""Categorical feature

- Item_Identifier
- Item_Fat_Content
- Item_Type
- Outlet_Identifier
- Outlet_Size
- Outlet_Location_Type
- Outlet_Type
"""

#checking the missing values
sales_data.isnull().sum()

"""Handling missing values

Mean -> average value

Mode -> Most repeated values
"""

#mean value of item_weight column
mean=sales_data['Item_Weight'].mean()
print(mean)

#filling the missing values in item weight column with mean value
sales_data['Item_Weight'].fillna(mean, inplace=True)

sales_data.isnull().sum()

"""Replacing the missing values in outlet_size column with mode"""

from ast import Lambda
mode = sales_data.pivot_table(values='Outlet_Size', columns='Outlet_Type', aggfunc=(lambda x: x.mode()[0]))

print(mode)

missing_values = sales_data['Outlet_Size'].isnull()

print(missing_values)

sales_data.loc[missing_values, 'Outlet_Size'] = sales_data.loc[missing_values,'Outlet_Type'].apply(lambda x: mode[x])

sales_data.isnull().sum()

"""Data analysis"""

#statistical data
sales_data.describe()

"""Numerical Feature"""

sns.set()

#Item_weight distribution
plt.figure(figsize=(6,6))
sns.distplot(sales_data['Item_Weight'])
plt.show()

#item visibility
plt.figure(figsize=(6,6))
sns.distplot(sales_data['Item_Visibility'])
plt.show()

#item_MRP
plt.figure(figsize=(6,6))
sns.distplot(sales_data['Item_MRP'])
plt.show()

#outlet_establishment_year
plt.figure(figsize=(6,6))
sns.countplot(x='Outlet_Establishment_Year', data=sales_data)
plt.show()

"""Categorical features"""

#item fat content
plt.figure(figsize=(6,6))
sns.countplot(x='Item_Fat_Content', data=sales_data)
plt.show()

#item type
plt.figure(figsize=(30,6))
sns.countplot(x='Item_Type', data=sales_data)
plt.show()

#outlet size
plt.figure(figsize=(6,6))
sns.countplot(x='Outlet_Size', data=sales_data)
plt.show()

"""Data preprocessing"""

sales_data.head()

sales_data['Item_Fat_Content'].value_counts()

sales_data.replace({'Item_Fat_Content':{'low fat':'Low Fat', 'LF':'Low Fat', 'reg':'Regular'}}, inplace=True)

sales_data['Item_Fat_Content'].value_counts()

"""Label Encoding"""

encoder = LabelEncoder()

#transforms all the categorical value to numerical values
sales_data['Item_Identifier'] = encoder.fit_transform(sales_data['Item_Identifier'])

sales_data['Item_Fat_Content'] = encoder.fit_transform(sales_data['Item_Fat_Content'])

sales_data['Item_Type'] = encoder.fit_transform(sales_data['Item_Type'])

sales_data['Outlet_Identifier'] = encoder.fit_transform(sales_data['Outlet_Identifier'])

sales_data['Outlet_Size'] = encoder.fit_transform(sales_data['Outlet_Size'])

sales_data['Outlet_Location_Type'] = encoder.fit_transform(sales_data['Outlet_Location_Type'])

sales_data['Outlet_Type'] = encoder.fit_transform(sales_data['Outlet_Type'])

sales_data.head()

"""Splitting data and targets"""

x=sales_data.drop(columns='Item_Outlet_Sales', axis=1)
y=sales_data['Item_Outlet_Sales']

"""splitting dataset into trainset and test set"""

x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2, random_state=2)

print(x.shape, x_train.shape, x_test.shape)

"""Model training"""

xgboost=XGBRegressor()

xgboost.fit(x_train,y_train)

"""Evaluation"""

#prediction on training data
x_train_pred=xgboost.predict(x_train)
x_train_pred_r= metrics.r2_score(y_train, x_train_pred)
print("R2 square for training data = ",x_train_pred_r)

#evaluation on test data
x_test_pred=xgboost.predict(x_test)
x_test_r = metrics.r2_score(y_test, x_test_pred)
print("R2 square for test data : ",x_test_r)

