# -*- coding: utf-8 -*-
"""Credit card fraud detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZZ8KQ_ZmkcWkivV4EtVCC2Acu2mDVRVx
"""

#importing dependencies
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

"""Data collection and processing"""

#loading the dataset to pandas dataframe
credit_data = pd.read_csv('/content/creditcard.csv')

#printing the first 5 rows of the dataset
credit_data.head()

#printing the last 5 rows of the dataset
credit_data.tail()

#getting the infromation about the data
credit_data.info()

#checking the nubmer of missing values in each column
credit_data.isnull().sum()

#checking the distrubtion of legit transaction and fradulant transaction
credit_data['Class'].value_counts()

"""This dataset is highly unbalanced

0 --> legit transaction
1 --> Fradulant transcation
"""

#seperating the data for analysis
legit = credit_data[credit_data.Class == 0] #labels that are equal to 0 is stored in legit variable
fraud = credit_data[credit_data.Class == 1] #labelsl that are equal to 1 is stored in fraud variable

print(legit.shape)
print(fraud.shape)

#getting the statistical data
legit.Amount.describe()
#gives statistical data for only Amount column from legit dataframe

#getting the statistical data for fraud column
fraud.Amount.describe()

#comparing the mean values for legit amount and fraud amount transaction
credit_data.groupby('Class').mean()

"""Undersamping the legit dataframe --> since legit class has more instances than fraud instances

number of fradulant rows --> 492

randomly selecting 492 instances from legit dataframe to match with fraud instances.
"""

legit_sample=legit.sample(n=492)

"""concatinating the legit_sample and fraud dataframe"""

new_data = pd.concat([legit_sample,fraud],axis=0)

new_data.shape
new_data['Class'].value_counts()

new_data.head()

new_data.groupby('Class').mean()

"""splitting the data into features and target"""

x = new_data.drop(columns ='Class', axis=1)
y = new_data['Class']

print(x,y)

"""splitting the data into training and test data"""

x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2, stratify=y, random_state=2)

print(x.shape, x_train.shape, x_test.shape)

"""Model training --> Logistic Regression"""

model=LogisticRegression()

#training the model using training dataset
model.fit(x_train,y_train)

"""Model evaluation

Accuracy score
"""

#accuracy score on training dataset
x_train_predict = model.predict(x_train)
x_train_accuracy = accuracy_score(x_train_predict,y_train)
print("Accuracy on Training data : ",x_train_accuracy)

#accuracy score on test dataset
x_test_prediction = model.predict(x_test)
x_test_accuracy = accuracy_score(x_test_prediction,y_test)
print("Accuracy on test data : ",x_test_accuracy)

"""predicting model"""

input_data=(1,-0.966271711572087,-0.185226008082898,1.79299333957872,-0.863291275036453,-0.0103088796030823,1.24720316752486,0.23760893977178,0.377435874652262,-1.38702406270197,-0.0549519224713749,-0.226487263835401,0.178228225877303,0.507756869957169,-0.28792374549456,-0.631418117709045,-1.0596472454325,-0.684092786345479,1.96577500349538,-1.2326219700892,-0.208037781160366,-0.108300452035545,0.00527359678253453,-0.190320518742841,-1.17557533186321,0.647376034602038,-0.221928844458407,0.0627228487293033,0.0614576285006353,123.5)

input_data_as_numpy_array=np.asarray(input_data)

input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)

prediction = model.predict(input_data_reshaped)

print(prediction)

if(prediction[0]==0):
  print("The transaction is legit")
else:
  print("The transaction is fraud")

